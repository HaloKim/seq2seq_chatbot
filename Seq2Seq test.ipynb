{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.5.6"},"colab":{"name":"Seq2Seq test 원본.ipynb","provenance":[],"collapsed_sections":[]}},"cells":[{"cell_type":"code","metadata":{"id":"rdeK22xB-xk7","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":315},"executionInfo":{"status":"ok","timestamp":1599198011131,"user_tz":-540,"elapsed":3763,"user":{"displayName":"김광륜","photoUrl":"","userId":"00196653692039337889"}},"outputId":"280c28dc-8307-4e3e-c454-99dc407d7189"},"source":["!pip install konlpy"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: konlpy in /usr/local/lib/python3.6/dist-packages (0.5.2)\n","Requirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.6/dist-packages (from konlpy) (4.2.6)\n","Requirement already satisfied: beautifulsoup4==4.6.0 in /usr/local/lib/python3.6/dist-packages (from konlpy) (4.6.0)\n","Requirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.6/dist-packages (from konlpy) (1.18.5)\n","Requirement already satisfied: tweepy>=3.7.0 in /usr/local/lib/python3.6/dist-packages (from konlpy) (3.9.0)\n","Requirement already satisfied: JPype1>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from konlpy) (1.0.2)\n","Requirement already satisfied: colorama in /usr/local/lib/python3.6/dist-packages (from konlpy) (0.4.3)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tweepy>=3.7.0->konlpy) (1.3.0)\n","Requirement already satisfied: requests[socks]>=2.11.1 in /usr/local/lib/python3.6/dist-packages (from tweepy>=3.7.0->konlpy) (2.23.0)\n","Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tweepy>=3.7.0->konlpy) (1.15.0)\n","Requirement already satisfied: typing-extensions; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from JPype1>=0.7.0->konlpy) (3.7.4.3)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->tweepy>=3.7.0->konlpy) (3.1.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (2020.6.20)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (1.24.3)\n","Requirement already satisfied: PySocks!=1.5.7,>=1.5.6; extra == \"socks\" in /usr/local/lib/python3.6/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (1.7.1)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Mp7ZrfPf-qiM","colab_type":"code","colab":{}},"source":["from konlpy.tag import Okt\n","from keras import layers\n","import re\n","import pandas as pd\n","import numpy as np\n","from keras import models\n","import pickle"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"NX6Aku7A-qiP","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":437},"executionInfo":{"status":"ok","timestamp":1599198013466,"user_tz":-540,"elapsed":6088,"user":{"displayName":"김광륜","photoUrl":"","userId":"00196653692039337889"}},"outputId":"f382d134-27f5-4bb0-d5b1-4b1df7e74fb4"},"source":["from keras.models import load_model\n","s2s = load_model('seq2seq_model.h5')\n","s2s.summary()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Model: \"functional_1\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_1 (InputLayer)            [(None, None)]       0                                            \n","__________________________________________________________________________________________________\n","input_2 (InputLayer)            [(None, None)]       0                                            \n","__________________________________________________________________________________________________\n","embedding (Embedding)           (None, None, 100)    233800      input_1[0][0]                    \n","__________________________________________________________________________________________________\n","embedding_1 (Embedding)         (None, None, 100)    233800      input_2[0][0]                    \n","__________________________________________________________________________________________________\n","lstm (LSTM)                     [(None, 128), (None, 117248      embedding[0][0]                  \n","__________________________________________________________________________________________________\n","lstm_1 (LSTM)                   [(None, None, 128),  117248      embedding_1[0][0]                \n","                                                                 lstm[0][1]                       \n","                                                                 lstm[0][2]                       \n","__________________________________________________________________________________________________\n","dense (Dense)                   (None, None, 2338)   301602      lstm_1[0][0]                     \n","==================================================================================================\n","Total params: 1,003,698\n","Trainable params: 1,003,698\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"iuFnktW--qiS","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":140},"executionInfo":{"status":"ok","timestamp":1599198013467,"user_tz":-540,"elapsed":6082,"user":{"displayName":"김광륜","photoUrl":"","userId":"00196653692039337889"}},"outputId":"b62f6cd7-26af-4e95-f5f8-de5bb416e925"},"source":["s2s.layers"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[<tensorflow.python.keras.engine.input_layer.InputLayer at 0x7f26b29f1cc0>,\n"," <tensorflow.python.keras.engine.input_layer.InputLayer at 0x7f26b29a7320>,\n"," <tensorflow.python.keras.layers.embeddings.Embedding at 0x7f26b29a74a8>,\n"," <tensorflow.python.keras.layers.embeddings.Embedding at 0x7f26b29a7860>,\n"," <tensorflow.python.keras.layers.recurrent_v2.LSTM at 0x7f26b29a7940>,\n"," <tensorflow.python.keras.layers.recurrent_v2.LSTM at 0x7f26b29e5278>,\n"," <tensorflow.python.keras.layers.core.Dense at 0x7f26b29e5a90>]"]},"metadata":{"tags":[]},"execution_count":4}]},{"cell_type":"code","metadata":{"id":"OrQf3lch-qiX","colab_type":"code","colab":{}},"source":["# 태그 단어\n","PAD = \"<PADDING>\"   # 패딩\n","STA = \"<START>\"     # 시작\n","END = \"<END>\"       # 끝\n","OOV = \"<OOV>\"       # 없는 단어(Out of Vocabulary)\n","\n","# 태그 인덱스\n","PAD_INDEX = 0\n","STA_INDEX = 1\n","END_INDEX = 2\n","OOV_INDEX = 3\n","\n","# 데이터 타입\n","ENCODER_INPUT  = 0\n","DECODER_INPUT  = 1\n","DECODER_TARGET = 2\n","\n","# 한 문장에서 단어 시퀀스의 최대 개수\n","max_sequences = 30\n","\n","# 임베딩 벡터 차원\n","embedding_dim = 100\n","\n","# LSTM 히든레이어 차원\n","lstm_hidden_dim = 128\n","\n","# 정규 표현식 필터\n","RE_FILTER = re.compile(\"[.,!?\\\"':;~()]\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"uZXcV5KS-qiZ","colab_type":"code","colab":{}},"source":["# 형태소분석 함수\n","def pos_tag(sentences):\n","    \n","    # KoNLPy 형태소분석기 설정\n","    tagger = Okt()\n","    \n","    # 문장 품사 변수 초기화\n","    sentences_pos = []\n","    \n","    # 모든 문장 반복\n","    for sentence in sentences:\n","        # 특수기호 제거\n","        sentence = re.sub(RE_FILTER, \"\", sentence)\n","        \n","        # 배열인 형태소분석의 출력을 띄어쓰기로 구분하여 붙임\n","        sentence = \" \".join(tagger.morphs(sentence))\n","        sentences_pos.append(sentence)\n","        \n","    return sentences_pos"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1aYiRO__-qic","colab_type":"code","colab":{}},"source":["# 단어와 인덱스의 딕셔너리 생성\n","with open('w2i.pkl', 'rb') as f:\n","    word_to_index = pickle.load(f)\n","with open('i2w.pkl', 'rb') as f:\n","    index_to_word = pickle.load(f)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"sQdpqEem-qie","colab_type":"code","colab":{}},"source":["# 문장을 인덱스로 변환\n","def convert_text_to_index(sentences, vocabulary, type): \n","    \n","    sentences_index = []\n","    \n","    # 모든 문장에 대해서 반복\n","    for sentence in sentences:\n","        sentence_index = []\n","        \n","        # 디코더 입력일 경우 맨 앞에 START 태그 추가\n","        if type == DECODER_INPUT:\n","            sentence_index.extend([vocabulary[STA]])\n","        \n","        # 문장의 단어들을 띄어쓰기로 분리\n","        for word in sentence.split():\n","            if vocabulary.get(word) is not None:\n","                # 사전에 있는 단어면 해당 인덱스를 추가\n","                sentence_index.extend([vocabulary[word]])\n","            else:\n","                # 사전에 없는 단어면 OOV 인덱스를 추가\n","                sentence_index.extend([vocabulary[OOV]])\n","\n","        # 최대 길이 검사\n","        if type == DECODER_TARGET:\n","            # 디코더 목표일 경우 맨 뒤에 END 태그 추가\n","            if len(sentence_index) >= max_sequences:\n","                sentence_index = sentence_index[:max_sequences-1] + [vocabulary[END]]\n","            else:\n","                sentence_index += [vocabulary[END]]\n","        else:\n","            if len(sentence_index) > max_sequences:\n","                sentence_index = sentence_index[:max_sequences]\n","            \n","        # 최대 길이에 없는 공간은 패딩 인덱스로 채움\n","        sentence_index += (max_sequences - len(sentence_index)) * [vocabulary[PAD]]\n","        \n","        # 문장의 인덱스 배열을 추가\n","        sentences_index.append(sentence_index)\n","\n","    return np.asarray(sentences_index)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"IQ_v1Qgw-qig","colab_type":"text"},"source":["# 훈련모델"]},{"cell_type":"code","metadata":{"id":"cYv0L7cE_mYS","colab_type":"code","colab":{}},"source":["# 학습 방법 설정\n","# s2s.compile(optimizer='rmsprop',\n","#               loss='categorical_crossentropy',\n","#               metrics=['accuracy'])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"lnSNYrs-AX8d","colab_type":"code","colab":{}},"source":["length = 2338\n","# 입력 문장의 인덱스 시퀀스를 입력으로 받음\n","encoder_inputs = layers.Input(shape=(None,))\n","\n","# 임베딩 레이어\n","encoder_outputs = layers.Embedding(length, embedding_dim)(encoder_inputs)\n","\n","# return_state가 True면 상태값 리턴\n","# LSTM은 state_h(hidden state)와 state_c(cell state) 2개의 상태 존재\n","encoder_outputs, state_h, state_c = layers.LSTM(lstm_hidden_dim,\n","                                                dropout=0.1,\n","                                                recurrent_dropout=0.5,\n","                                                return_state=True)(encoder_outputs)\n","\n","# 히든 상태와 셀 상태를 하나로 묶음\n","encoder_states = [state_h, state_c]\n","\n","# 목표 문장의 인덱스 시퀀스를 입력으로 받음\n","decoder_inputs = layers.Input(shape=(None,))\n","\n","# 임베딩 레이어\n","decoder_embedding = layers.Embedding(length, embedding_dim)\n","decoder_outputs = decoder_embedding(decoder_inputs)\n","\n","# 인코더와 달리 return_sequences를 True로 설정하여 모든 타임 스텝 출력값 리턴\n","# 모든 타임 스텝의 출력값들을 다음 레이어의 Dense()로 처리하기 위함\n","decoder_lstm = layers.LSTM(lstm_hidden_dim,\n","                           dropout=0.1,\n","                           recurrent_dropout=0.5,\n","                           return_state=True,\n","                           return_sequences=True)\n","\n","decoder_dense = layers.Dense(length, activation='softmax')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"BrmqiiVmkPxz","colab_type":"code","colab":{}},"source":["#--------------------------------------------\n","# 훈련 모델 인코더 정의\n","#--------------------------------------------\n","length = 2338\n","# 입력 문장의 인덱스 시퀀스를 입력으로 받음\n","encoder_inputs = layers.Input(shape=(None,))\n","\n","# 임베딩 레이어\n","encoder_outputs = layers.Embedding(length, embedding_dim)(encoder_inputs)\n","\n","# return_state가 True면 상태값 리턴\n","# LSTM은 state_h(hidden state)와 state_c(cell state) 2개의 상태 존재\n","encoder_outputs, state_h, state_c = layers.LSTM(lstm_hidden_dim,\n","                                                dropout=0.1,\n","                                                recurrent_dropout=0.5,\n","                                                return_state=True)(encoder_outputs)\n","\n","# 히든 상태와 셀 상태를 하나로 묶음\n","encoder_states = [state_h, state_c]\n","\n","\n","#--------------------------------------------\n","# 훈련 모델 디코더 정의\n","#--------------------------------------------\n","\n","# 목표 문장의 인덱스 시퀀스를 입력으로 받음\n","decoder_inputs = layers.Input(shape=(None,))\n","\n","# 임베딩 레이어\n","decoder_embedding = layers.Embedding(length, embedding_dim)\n","decoder_outputs = decoder_embedding(decoder_inputs)\n","\n","\n","# 인코더와 달리 return_sequences를 True로 설정하여 모든 타임 스텝 출력값 리턴\n","# 모든 타임 스텝의 출력값들을 다음 레이어의 Dense()로 처리하기 위함\n","decoder_lstm = layers.LSTM(lstm_hidden_dim,\n","                           dropout=0.1,\n","                           recurrent_dropout=0.5,\n","                           return_state=True,\n","                           return_sequences=True)\n","\n","\n","\n","# initial_state를 인코더의 상태로 초기화\n","decoder_outputs, _, _ = decoder_lstm(decoder_outputs,\n","                                     initial_state=encoder_states)\n","\n","# 단어의 개수만큼 노드의 개수를 설정하여 원핫 형식으로 각 단어 인덱스를 출력\n","decoder_dense = layers.Dense(length, activation='softmax')\n","decoder_outputs = decoder_dense(decoder_outputs)\n","\n","#--------------------------------------------\n","# 훈련 모델 정의\n","#--------------------------------------------\n","\n","# 입력과 출력으로 함수형 API 모델 생성\n","model = models.Model([encoder_inputs, decoder_inputs], decoder_outputs)\n","\n","# 학습 방법 설정\n","model.compile(optimizer='rmsprop',\n","              loss='categorical_crossentropy',\n","              metrics=['accuracy'])\n","model.load_weights(\"/content/seq2seq_model.h5\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"H5ZhIOhq-qij","colab_type":"code","colab":{}},"source":["#--------------------------------------------\n","#  예측 모델 인코더 정의\n","#--------------------------------------------\n","\n","# 훈련 모델의 인코더 상태를 사용하여 예측 모델 인코더 설정\n","encoder_model = models.Model(encoder_inputs, encoder_states)\n","\n","#--------------------------------------------\n","# 예측 모델 디코더 정의\n","#--------------------------------------------\n","\n","# 예측시에는 훈련시와 달리 타임 스텝을 한 단계씩 수행\n","# 매번 이전 디코더 상태를 입력으로 받아서 새로 설정\n","decoder_state_input_h = layers.Input(shape=(lstm_hidden_dim,))\n","decoder_state_input_c = layers.Input(shape=(lstm_hidden_dim,))\n","decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]    \n","\n","# 임베딩 레이어\n","decoder_outputs = decoder_embedding(decoder_inputs)\n","\n","# LSTM 레이어\n","decoder_outputs, state_h, state_c = decoder_lstm(decoder_outputs,\n","                                                 initial_state=decoder_states_inputs)\n","\n","# 히든 상태와 셀 상태를 하나로 묶음\n","decoder_states = [state_h, state_c]\n","\n","# Dense 레이어를 통해 원핫 형식으로 각 단어 인덱스를 출력\n","decoder_outputs = decoder_dense(decoder_outputs)\n","\n","# 예측 모델 디코더 설정\n","decoder_model = models.Model([decoder_inputs] + decoder_states_inputs,\n","                      [decoder_outputs] + decoder_states)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ep5ODpTU-qil","colab_type":"code","colab":{}},"source":["# 인덱스를 문장으로 변환\n","def convert_index_to_text(indexs, vocabulary): \n","    \n","    sentence = ''\n","\n","    # 모든 문장에 대해서 반복\n","    for index in indexs:\n","        if index == END_INDEX:\n","            # 종료 인덱스면 중지\n","            break;\n","        if vocabulary.get(index) is not None:\n","            # 사전에 있는 인덱스면 해당 단어를 추가\n","            sentence += vocabulary[index]\n","        else:\n","            # 사전에 없는 인덱스면 OOV 단어를 추가\n","            sentence.extend([vocabulary[OOV_INDEX]])\n","            \n","        # 빈칸 추가\n","        sentence += ' '\n","\n","    return sentence"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"eIMTEdvs-qio","colab_type":"code","colab":{}},"source":["# 예측을 위한 입력 생성\n","def make_predict_input(sentence):\n","\n","    sentences = []\n","    sentences.append(sentence)\n","    sentences = pos_tag(sentences)\n","    input_seq = convert_text_to_index(sentences, word_to_index, ENCODER_INPUT)\n","    \n","    return input_seq"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"mJkRo7ar-qip","colab_type":"code","colab":{}},"source":["# 텍스트 생성\n","def generate_text(input_seq):\n","\n","\n","    # 입력을 인코더에 넣어 마지막 상태 구함\n","    states = encoder_model.predict(input_seq)\n","  \n","    # 목표 시퀀스 초기화\n","    target_seq = np.zeros((1, 1))\n","    \n","    # 목표 시퀀스의 첫 번째에 <START> 태그 추가\n","    target_seq[0, 0] = STA_INDEX\n","    \n","    # 인덱스 초기화\n","    indexs = []\n","    # 디코더 타임 스텝 반복\n","    while 1:\n","        # 디코더로 현재 타임 스텝 출력 구함\n","        # 처음에는 인코더 상태를, 다음부터 이전 디코더 상태로 초기화\n","        \n","\n","        decoder_outputs, state_h, state_c = decoder_model.predict(\n","                                                [target_seq] + states)\n","\n","        # 결과의 원핫인코딩 형식을 인덱스로 변환\n","        index = np.argmax(decoder_outputs[0, 0, :])\n","        indexs.append(index)\n","        \n","        # 종료 검사\n","        if index == END_INDEX or len(indexs) >= max_sequences:\n","            break\n","\n","        # 목표 시퀀스를 바로 이전의 출력으로 설정\n","        target_seq = np.zeros((1, 1))\n","        target_seq[0, 0] = index\n","        \n","        # 디코더의 이전 상태를 다음 디코더 예측에 사용\n","        states = [state_h, state_c]\n","\n","    # 인덱스를 문장으로 변환\n","    sentence = convert_index_to_text(indexs, index_to_word)\n","\n","    return sentence"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"x3vWoXQf-qis","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":70},"executionInfo":{"status":"ok","timestamp":1599198083473,"user_tz":-540,"elapsed":9751,"user":{"displayName":"김광륜","photoUrl":"","userId":"00196653692039337889"}},"outputId":"f5aabb1b-6df2-4309-b87b-a845957aa048"},"source":["# 문장을 인덱스로 변환\n","input_seq = make_predict_input('프로젝트 어떻게 만들어')\n","input_seq"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[1773, 1232, 1345,    0,    0,    0,    0,    0,    0,    0,    0,\n","           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","           0,    0,    0,    0,    0,    0,    0,    0]])"]},"metadata":{"tags":[]},"execution_count":17}]},{"cell_type":"code","metadata":{"id":"90w3zpCN-qiu","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1599198085837,"user_tz":-540,"elapsed":11906,"user":{"displayName":"김광륜","photoUrl":"","userId":"00196653692039337889"}},"outputId":"0ec0c9be-6473-482f-c109-54ecdf12477f"},"source":["# 예측 모델로 텍스트 생성\n","sentence = generate_text(input_seq)\n","sentence"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'프로젝트 를 생 성하겠습니다 '"]},"metadata":{"tags":[]},"execution_count":18}]},{"cell_type":"code","metadata":{"id":"zUMEaeWVuAcw","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]}]}